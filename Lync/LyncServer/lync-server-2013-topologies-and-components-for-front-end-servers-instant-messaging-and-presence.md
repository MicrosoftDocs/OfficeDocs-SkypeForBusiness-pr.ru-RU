---
title: "Lync Server 2013: топол. и компон. для серв. пер. плана, обмена мгн. сообщ. и свед. о присутствии"
TOCTitle: Топология и компоненты для серверов переднего плана, обмена мгновенными сообщениями и сведениями о присутствии
ms:assetid: f08ce7a1-d14e-4a54-9771-a82c870658bf
ms:mtpsurl: https://technet.microsoft.com/ru-ru/library/Gg412996(v=OCS.15)
ms:contentKeyID: 49311614
ms.date: 12/10/2016
mtps_version: v=OCS.15
ms.translationtype: HT
---

# Топология и компоненты для серверов переднего плана, обмена мгновенными сообщениями и сведениями о присутствии в Lync Server 2013

 

_**Дата изменения раздела:** 2016-12-08_

Для обмена мгновенными сообщениями и сведениями о присутствии требуются только следующие компоненты:

  - Серверы переднего плана организации или серверы Standard Edition. Функции обмена мгновенными сообщениями и сведениями о присутствии всегда включены на этих серверах.

  - Подсистема балансировки нагрузки, если используется пул Enterprise Editionпереднего плана. Дополнительные сведения см. в разделе [Требования к балансировке нагрузки в Lync Server 2013](lync-server-2013-load-balancing-requirements.md).

## Планирование развертывания интерфейсных пулов

Архитектура пула переднего плана в Lync Server 2013 была изменена, и эти изменения влияют на планирование и обслуживание пулов переднего плана.

Рекомендуется, чтобы все ваши пулы Enterprise Editionпереднего плана включали в себя хотя бы три сервера переднего плана. В Lync Server архитектура пулов переднего плана использует модель распределенных систем, в которой данные каждого пользователя хранятся на трех серверах переднего плана в пуле. Дополнительные сведения об этой новой архитектуре см. в разделе [Изменения топологии в Lync Server 2013](lync-server-2013-topology-changes.md).

Если вы не хотите развертывать три сервера Enterprise Editionпереднего плана, но хотите обеспечить аварийное восстановление, рекомендуем использовать Lync ServerStandard Edition и создать два пула с сопряженным резервом. Это позволит получить оптимальное решение аварийного восстановления всего с двумя серверами. Дополнительные сведения о топологиях и возможностях аварийного восстановления см. в разделе [Планирование высокой доступности и аварийного восстановления в Lync Server 2013](lync-server-2013-planning-for-high-availability-and-disaster-recovery.md).

## Планирование управления интерфейсными пулами

Для переднего плана следуйте инструкциям, приведенным в данном разделе.

## Проверка работоспособности пулов

С новой распределенной моделью для переднего плана для правильного функционирования пула в нем должно работать определенное число серверов. Существует два режима нехватки для пула

  - Нехватка кворума на уровне группы маршрутизации, что вызвано недостаточным количеством серверов-реплик для определенной группы маршрутизации. Группа маршрутизации — это агрегирование группы пользователей, размещенных в пуле. Каждая группа маршрутизации имеет три реплики в пуле: одна главная и две дополнительные.

  - Нехватка кворума на уровне пула, что вызвано недостаточным количеством серверов инициализации в пуле.

## Нехватка кворума на уровне группы маршрутизации

При первом запуске пула переднего плана необходимо, чтобы 85% серверов были установлены и запущены, как показано в следующей таблице. Если запущено меньшее количество серверов, службы могут зависнуть в состоянии запуска, а пул может вообще не запуститься.


<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>Общее количество серверов в пуле</th>
<th>Количество запущенных серверов, которое требуется для первого запуска пула</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>2</p></td>
<td><p>1</p></td>
</tr>
<tr class="even">
<td><p>3</p></td>
<td><p>3</p></td>
</tr>
<tr class="odd">
<td><p>4</p></td>
<td><p>3</p></td>
</tr>
<tr class="even">
<td><p>5</p></td>
<td><p>4</p></td>
</tr>
<tr class="odd">
<td><p>6</p></td>
<td><p>5</p></td>
</tr>
<tr class="even">
<td><p>7</p></td>
<td><p>5</p></td>
</tr>
<tr class="odd">
<td><p>8</p></td>
<td><p>6</p></td>
</tr>
<tr class="even">
<td><p>9</p></td>
<td><p>7</p></td>
</tr>
<tr class="odd">
<td><p>10</p></td>
<td><p>8</p></td>
</tr>
<tr class="even">
<td><p>11</p></td>
<td><p>9</p></td>
</tr>
<tr class="odd">
<td><p>12</p></td>
<td><p>10</p></td>
</tr>
</tbody>
</table>


При каждом последующем запуске пула 85% серверов должны быть запущены (как показано на таблице выше). Если невозможно запустить такое количество серверов (однако можно запустить столько серверов, чтобы избежать нехватку кворума на уровне пула), можно воспользоваться командлетом **Reset-CsPoolRegistrarState –ResetType QuorumLossRecovery** для восстановления пула из нехватку кворума на уровне группы маршрутизации и запуска хода выполнения. Подробнее об использовании данного командлета см. раздел [Reset-CsPoolRegistrarState](https://docs.microsoft.com/en-us/powershell/module/skype/Reset-CsPoolRegistrarState).

> [!NOTE]  
> Поскольку в Lync Server используется основная база данных SQL в качестве следящего сервера, то, если будет закрыта основная база данных, выполнено переключение на зеркальную копию и сброшено количество серверов переднего плана, перечисленных в таблице выше, то весь пул будет остановлен. Дополнительные сведения см. в статье <a href="http://go.microsoft.com/fwlink/?linkid=393672">Следящий сервер зеркального отображения базы данных</a>.

## Нехватка кворума на уровне пула

Для функционирования пула переднего плана не должно быть нехватки кворума на уровне пула. Если число работающих серверов становится ниже указанного в таблице функционального уровня, оставшиеся серверы в пуле остановят все службы Lync Server. Обратите внимание, что числовые данные в следующей таблице приведены при условии, что тыловое серверы запущены в пуле.


<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>Общее число серверов переднего плана в пуле</th>
<th>Число работающих серверов, требуемое для правильного функционирования пула</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>2</p></td>
<td><p>1</p></td>
</tr>
<tr class="even">
<td><p>3-4</p></td>
<td><p>Любые 2</p></td>
</tr>
<tr class="odd">
<td><p>5-6</p></td>
<td><p>Любые 3</p></td>
</tr>
<tr class="even">
<td><p>7</p></td>
<td><p>Любые 4</p></td>
</tr>
<tr class="odd">
<td><p>8-9</p></td>
<td><p>Любые 4 из первых 7 серверов</p></td>
</tr>
<tr class="even">
<td><p>10–12</p></td>
<td><p>Любые 5 из первых 9 серверов</p></td>
</tr>
</tbody>
</table>


В таблице выше "первые серверы" — это серверы, открытые первыми в хронологическом порядке при первом запуске пула. Чтобы определить такие серверы, можно воспользоваться командлетом **Get-CsComputer** с параметром **–PoolFqdn**. Данный командлет отобразит серверы в том порядке, в котором они представлены в топологии. Первые серверы в списке и будут "первыми серверами".

## Интерфейсные пулы с двумя серверами переднего плана

Мы не рекомендуем развертывать интерфейсный пул, содержащий всего два сервера переднего плана. Если вам все же потребуется развернуть такой пул, следуйте приведенным ниже рекомендациям:

  - В случае сбоя одного из двух этих серверов переднего плана вам следует как можно быстрее восстановить его работоспособность. Аналогичным образом, в случае обновления одного из двух серверов его также необходимо вернуть в рабочее состояние как можно быстрее.

  - Если по какой-либо причине требуется отключить оба сервера одновременно, после окончания простоя пула выполните следующие действия:
    
      - Рекомендуется перезагрузить оба сервера переднего плана одновременно.
    
      - Если это невозможно, следует включать их в порядке, обратном порядку их отключения.
    
      - Если и это невозможно, перед включением пула выполните следующий командлет:
        
            Reset-CsPoolRegistrarState -ResetType QuorumLossRecovery -PoolFQDN <FQDN>

## Дополнительные способы проверки работоспособности пулов

Для проверки функционирования пулов переднего плана требуется обратить внимание на еще несколько факторов.

  - При первом перемещении пользователей в пул обязательно убедитесь, что запущено не менее трех серверов переднего плана.

  - Если вы устанавливаете отношение связывания между данным пулом и другим пулом в целях обеспечения аварийного восстановления, по после этого вам следует убедиться, что данный пул имеет три одновременно работающих сервера переднего плана для правильной синхронизации данных с резервным пулом. Дополнительные сведения о возможностях связывания пулов и аварийного восстановления см. в разделе [Планирование высокой доступности и аварийного восстановления в Lync Server 2013](lync-server-2013-planning-for-high-availability-and-disaster-recovery.md).

## Повышение уровня стабильности обновления пулов

Для обновления или исправления серверов в пуле переднего плана следуйте инструкциям, представленным в разделе [Обновление серверов переднего плана в Lync Server 2013](lync-server-2013-upgrade-or-update-front-end-servers.md), а также следующим рекомендациям:

  - При переходе с одного домена обновления на другой для выполнения обновлений (следуя инструкциям в разделе [Обновление серверов переднего плана в Lync Server 2013](lync-server-2013-upgrade-or-update-front-end-servers.md)), воспользуйтесь командлетом **Get-CsPoolUpgradeReadinessState** и проверьте состояние готовности. Можно повысить уровень стабильности обновлений, добавив 20 минут ожидания между каждым доменом обновления после достижения состояния "Готово". Если в течение 20 минут отображается состояние **Не готово**, перезапустите 20-минутный таймер. Кроме того, можно выполнить командлет **Get-CsPoolFabricState** до и после 20-минутного интервала и убедиться, что никакие изменения в основные и дополнительные группы маршрутизации внесены не были.

  - Не переходите к следующему домену обновления, если какой-либо из серверов в последнем исправленном домене обновления завис или не перезапустился. Это также актуально, если не запускается любой из серверов в обновлении. Выполните командлет **Get-CsPoolFabricState**, чтобы убедиться, что все группы маршрутизации имеют одну основную и по крайней мере одну дополнительную группу. Это подтвердит наличие службы для всех пользователей.

  - Если у некоторых пользователей есть служба, а других — нет, запустите командлет **Get-CsPoolFabricState** с параметром –Verbose для обнаружения групп маршрутизации с отсутствующими репликами. Не перезапускайте весь пул на первом шаге устранения неполадки. Подробнее о данном командлете см. раздел [Get-CsPoolFabricState](https://docs.microsoft.com/en-us/powershell/module/skype/Get-CsPoolFabricState).

  - Убедитесь, что все окна средства просмотра событий или системного монитора закрыты для выполнения установок или удалений в Windows Fabric.

## Изменение конфигурации интерфейсного пула

При добавлении серверов переднего плана в пул, их удалении из пула и публикации новой топологии следуйте приведенным ниже рекомендациям:

  - После публикации новой топологии следует перезапустить каждый сервер переднего плана в пуле. Перезапускайте их по одному.

  - Если во время изменения конфигурации был отключен весь пул, после публикации новой топологии запустите следующий командлет:
    
        Reset-CsPoolRegistrarState -PoolFQDN <PoolFQDN> -ResetType ServiceReset

Если сервер переднего плана ломается и вряд ли будет заменен только через несколько дней или позднее, удалите этот сервер из топологии. Когда новый сервер переднего плана вновь станет доступен, добавьте его в топологию.

